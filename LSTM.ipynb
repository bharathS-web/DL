{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess Data\n",
    "file_path = r\"Dataset\\\\en.txt\"\n",
    "\n",
    "# Open the file and read the sentences\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "# Clean the sentences (remove newline characters and extra spaces)\n",
    "sentences = [sentence.strip() for sentence in sentences]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sentences[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dataset)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "input_sequences = []\n",
    "for line in dataset:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "max_seq_length = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_length, padding='pre')\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = keras.utils.to_categorical(y, num_classes=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhar\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Define LSTM Model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 128, input_length=max_seq_length - 1),\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.LSTM(256),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2183/2183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 687ms/step - accuracy: 0.0519 - loss: 6.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24103228800>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Train Model\n",
    "model.fit(X, y, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Sentence Completions\n",
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_length - 1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is the meeting\n"
     ]
    }
   ],
   "source": [
    "# Example Completion\n",
    "print(generate_text(\"where is  \", 2 ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# Load WikiText-2 dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Tokenize the dataset\n",
    "counter = Counter()\n",
    "for line in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = Vocab(counter, min_freq=2, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(text_iter, vocab, tokenizer, seq_length=30):\n",
    "    sequences = []\n",
    "    for line in text_iter:\n",
    "        tokens = tokenizer(line)\n",
    "        indices = [vocab[token] for token in tokens]\n",
    "        sequences.extend(indices)\n",
    "    \n",
    "    # Convert list to PyTorch tensor\n",
    "    text_tensor = torch.tensor(sequences, dtype=torch.long)\n",
    "    \n",
    "    # Create input-output pairs\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(text_tensor) - seq_length):\n",
    "        inputs.append(text_tensor[i:i+seq_length])\n",
    "        targets.append(text_tensor[i+1:i+seq_length+1])\n",
    "\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "X_train, y_train = text_to_tensor(train_iter, vocab, tokenizer)\n",
    "print(f\"Training Data Shape: {X_train.shape}, {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(LSTMLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "# Define model parameters\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "\n",
    "# Instantiate model\n",
    "model = LSTMLanguageModel(vocab_size, embed_size, hidden_size, num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "seq_length = 30\n",
    "hidden = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        inputs = X_train[i:i+batch_size].to(device)\n",
    "        targets = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(inputs, hidden)\n",
    "\n",
    "        loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(X_train):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Example Usage\u001b[39;00m\n\u001b[0;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe future of AI is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 25\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text(prompt, model, \u001b[43mvocab\u001b[49m, tokenizer)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, generated_text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text(prompt, model, vocab, tokenizer, seq_length=10, max_words=50):\n",
    "    model.eval()\n",
    "    \n",
    "    words = tokenizer(prompt)\n",
    "    indices = [vocab[token] for token in words]\n",
    "    input_seq = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    generated_words = words\n",
    "\n",
    "    hidden = None\n",
    "    for _ in range(max_words):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        next_word_index = output.argmax(dim=-1)[:, -1].item()\n",
    "        next_word = vocab.lookup_token(next_word_index)\n",
    "        \n",
    "        generated_words.append(next_word)\n",
    "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[next_word_index]], dtype=torch.long).to(device)], dim=1)\n",
    "\n",
    "    return \" \".join(generated_words)\n",
    "\n",
    "# Example Usage\n",
    "prompt = \"The future of AI is\"\n",
    "generated_text = generate_text(prompt, model, vocab, tokenizer)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# language translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = r\"Dataset\\\\en.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = file.readlines()\n",
    "english_sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "\n",
    "file_path = r\"Dataset\\\\ta.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = file.readlines()\n",
    "tamil_sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(sentences):\n",
    "    tokenized = [sentence.lower().replace(\",\", \"\").replace(\"?\", \"\").split() for sentence in sentences]\n",
    "    return tokenized\n",
    "\n",
    "# Create vocabularies\n",
    "def build_vocab(tokenized_sentences):\n",
    "    counter = Counter()\n",
    "    for sentence in tokenized_sentences:\n",
    "        counter.update(sentence)\n",
    "    vocab = {word: i + 2 for i, (word, _) in enumerate(counter.most_common())}  # Start index from 2\n",
    "    vocab[\"<pad>\"] = 0\n",
    "    vocab[\"<unk>\"] = 1\n",
    "    return vocab\n",
    "\n",
    "# Convert sentences to numerical sequences\n",
    "def encode_sentences(tokenized_sentences, vocab):\n",
    "    return [[vocab.get(word, vocab[\"<unk>\"]) for word in sentence] for sentence in tokenized_sentences]\n",
    "\n",
    "# Tokenization\n",
    "eng_tokenized = tokenize(english_sentences)\n",
    "tam_tokenized = tokenize(tamil_sentences)\n",
    "\n",
    "# Build vocabulary\n",
    "eng_vocab = build_vocab(eng_tokenized)\n",
    "tam_vocab = build_vocab(tam_tokenized)\n",
    "\n",
    "# Convert text to sequences\n",
    "eng_sequences = encode_sentences(eng_tokenized, eng_vocab)\n",
    "tam_sequences = encode_sentences(tam_tokenized, tam_vocab)\n",
    "\n",
    "# Pad sequences\n",
    "eng_sequences = pad_sequence([torch.tensor(seq) for seq in eng_sequences], batch_first=True, padding_value=0)\n",
    "tam_sequences = pad_sequence([torch.tensor(seq) for seq in tam_sequences], batch_first=True, padding_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the LSTM Encoder-Decoder Model\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, embed_dim=128, hidden_dim=256):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n",
    "        self.encoder_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n",
    "        self.decoder_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        # Encoder\n",
    "        enc_emb = self.encoder_embedding(encoder_input)\n",
    "        _, (hidden, cell) = self.encoder_lstm(enc_emb)\n",
    "\n",
    "        # Decoder\n",
    "        dec_emb = self.decoder_embedding(decoder_input)\n",
    "        decoder_output, _ = self.decoder_lstm(dec_emb, (hidden, cell))\n",
    "        output = self.fc(decoder_output)  # Predict next words\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model setup\n",
    "input_dim = len(eng_vocab)\n",
    "output_dim = len(tam_vocab)\n",
    "model = Seq2SeqModel(input_dim, output_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare training data\n",
    "X_train = eng_sequences\n",
    "y_train = tam_sequences\n",
    "\n",
    "# Shift decoder input (teacher forcing)\n",
    "decoder_input = y_train[:, :-1]  # Remove last token\n",
    "decoder_target = y_train[:, 1:]  # Remove first token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Loss: 5.9562\n",
      "Epoch [10/1000], Loss: 5.4402\n",
      "Epoch [20/1000], Loss: 4.1186\n",
      "Epoch [30/1000], Loss: 2.4821\n",
      "Epoch [40/1000], Loss: 1.1143\n",
      "Epoch [50/1000], Loss: 0.4310\n",
      "Epoch [60/1000], Loss: 0.1852\n",
      "Epoch [70/1000], Loss: 0.0945\n",
      "Epoch [80/1000], Loss: 0.0576\n",
      "Epoch [90/1000], Loss: 0.0402\n",
      "Epoch [100/1000], Loss: 0.0308\n",
      "Epoch [110/1000], Loss: 0.0251\n",
      "Epoch [120/1000], Loss: 0.0212\n",
      "Epoch [130/1000], Loss: 0.0183\n",
      "Epoch [140/1000], Loss: 0.0161\n",
      "Epoch [150/1000], Loss: 0.0143\n",
      "Epoch [160/1000], Loss: 0.0129\n",
      "Epoch [170/1000], Loss: 0.0116\n",
      "Epoch [180/1000], Loss: 0.0106\n",
      "Epoch [190/1000], Loss: 0.0097\n",
      "Epoch [200/1000], Loss: 0.0089\n",
      "Epoch [210/1000], Loss: 0.0082\n",
      "Epoch [220/1000], Loss: 0.0076\n",
      "Epoch [230/1000], Loss: 0.0071\n",
      "Epoch [240/1000], Loss: 0.0066\n",
      "Epoch [250/1000], Loss: 0.0062\n",
      "Epoch [260/1000], Loss: 0.0058\n",
      "Epoch [270/1000], Loss: 0.0055\n",
      "Epoch [280/1000], Loss: 0.0052\n",
      "Epoch [290/1000], Loss: 0.0049\n",
      "Epoch [300/1000], Loss: 0.0046\n",
      "Epoch [310/1000], Loss: 0.0044\n",
      "Epoch [320/1000], Loss: 0.0042\n",
      "Epoch [330/1000], Loss: 0.0040\n",
      "Epoch [340/1000], Loss: 0.0038\n",
      "Epoch [350/1000], Loss: 0.0036\n",
      "Epoch [360/1000], Loss: 0.0034\n",
      "Epoch [370/1000], Loss: 0.0033\n",
      "Epoch [380/1000], Loss: 0.0031\n",
      "Epoch [390/1000], Loss: 0.0030\n",
      "Epoch [400/1000], Loss: 0.0029\n",
      "Epoch [410/1000], Loss: 0.0028\n",
      "Epoch [420/1000], Loss: 0.0027\n",
      "Epoch [430/1000], Loss: 0.0026\n",
      "Epoch [440/1000], Loss: 0.0025\n",
      "Epoch [450/1000], Loss: 0.0024\n",
      "Epoch [460/1000], Loss: 0.0023\n",
      "Epoch [470/1000], Loss: 0.0022\n",
      "Epoch [480/1000], Loss: 0.0021\n",
      "Epoch [490/1000], Loss: 0.0021\n",
      "Epoch [500/1000], Loss: 0.0020\n",
      "Epoch [510/1000], Loss: 0.0019\n",
      "Epoch [520/1000], Loss: 0.0019\n",
      "Epoch [530/1000], Loss: 0.0018\n",
      "Epoch [540/1000], Loss: 0.0018\n",
      "Epoch [550/1000], Loss: 0.0017\n",
      "Epoch [560/1000], Loss: 0.0017\n",
      "Epoch [570/1000], Loss: 0.0016\n",
      "Epoch [580/1000], Loss: 0.0016\n",
      "Epoch [590/1000], Loss: 0.0015\n",
      "Epoch [600/1000], Loss: 0.0015\n",
      "Epoch [610/1000], Loss: 0.0014\n",
      "Epoch [620/1000], Loss: 0.0014\n",
      "Epoch [630/1000], Loss: 0.0014\n",
      "Epoch [640/1000], Loss: 0.0013\n",
      "Epoch [650/1000], Loss: 0.0013\n",
      "Epoch [660/1000], Loss: 0.0013\n",
      "Epoch [670/1000], Loss: 0.0012\n",
      "Epoch [680/1000], Loss: 0.0012\n",
      "Epoch [690/1000], Loss: 0.0012\n",
      "Epoch [700/1000], Loss: 0.0011\n",
      "Epoch [710/1000], Loss: 0.0011\n",
      "Epoch [720/1000], Loss: 0.0011\n",
      "Epoch [730/1000], Loss: 0.0011\n",
      "Epoch [740/1000], Loss: 0.0010\n",
      "Epoch [750/1000], Loss: 0.0010\n",
      "Epoch [760/1000], Loss: 0.0010\n",
      "Epoch [770/1000], Loss: 0.0010\n",
      "Epoch [780/1000], Loss: 0.0009\n",
      "Epoch [790/1000], Loss: 0.0009\n",
      "Epoch [800/1000], Loss: 0.0009\n",
      "Epoch [810/1000], Loss: 0.0009\n",
      "Epoch [820/1000], Loss: 0.0009\n",
      "Epoch [830/1000], Loss: 0.0008\n",
      "Epoch [840/1000], Loss: 0.0008\n",
      "Epoch [850/1000], Loss: 0.0008\n",
      "Epoch [860/1000], Loss: 0.0008\n",
      "Epoch [870/1000], Loss: 0.0008\n",
      "Epoch [880/1000], Loss: 0.0008\n",
      "Epoch [890/1000], Loss: 0.0008\n",
      "Epoch [900/1000], Loss: 0.0007\n",
      "Epoch [910/1000], Loss: 0.0007\n",
      "Epoch [920/1000], Loss: 0.0007\n",
      "Epoch [930/1000], Loss: 0.0007\n",
      "Epoch [940/1000], Loss: 0.0007\n",
      "Epoch [950/1000], Loss: 0.0007\n",
      "Epoch [960/1000], Loss: 0.0007\n",
      "Epoch [970/1000], Loss: 0.0006\n",
      "Epoch [980/1000], Loss: 0.0006\n",
      "Epoch [990/1000], Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "batch_size = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train, decoder_input)\n",
    "    loss = criterion(outputs.view(-1, output_dim), decoder_target.reshape(-1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Translation function\n",
    "def translate(sentence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = encode_sentences(tokenize([sentence]), eng_vocab)\n",
    "        sequence = pad_sequence([torch.tensor(seq) for seq in sequence], batch_first=True, padding_value=0)\n",
    "        \n",
    "        decoder_input = torch.zeros((1, sequence.shape[1]), dtype=torch.long)  # Empty decoder input\n",
    "        states_value = model(sequence, decoder_input)\n",
    "        predicted_seq = torch.argmax(states_value, dim=-1).squeeze(0).tolist()\n",
    "        \n",
    "        output_sentence = ' '.join([word for word, index in tam_vocab.items() if index in predicted_seq])\n",
    "        return output_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "நான்\n"
     ]
    }
   ],
   "source": [
    "# Test Translation\n",
    "print(translate(\"I like that movie.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input Shape: (4, 4)\n",
      "Decoder Input Shape: (4, 3)\n",
      "Decoder Target Shape: (4, 3)\n",
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0625 - loss: 2.6393\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6250 - loss: 2.6221\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 2.6043\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 2.5854\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 2.5649\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 2.5420\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 2.5160\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 2.4861\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 2.4514\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 2.4107\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 2.3628\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 2.3063\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6875 - loss: 2.2392\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6250 - loss: 2.1597\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6250 - loss: 2.0658\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6250 - loss: 1.9560\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5625 - loss: 1.8298\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5625 - loss: 1.6893\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5625 - loss: 1.5407\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5625 - loss: 1.3945\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5625 - loss: 1.2619\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5625 - loss: 1.1478\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5625 - loss: 1.0459\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5625 - loss: 0.9465\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6250 - loss: 0.8488\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.7635\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8125 - loss: 0.6992\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8125 - loss: 0.6472\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.5901\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8750 - loss: 0.5207\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.4574\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.4158\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8750 - loss: 0.3818\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8750 - loss: 0.3397\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8750 - loss: 0.2926\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8750 - loss: 0.2525\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.2248\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.2014\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.1718\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.1430\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.1223\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8750 - loss: 0.1068\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0929\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0789\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.0659\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8750 - loss: 0.0554\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0477\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0421\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.0373\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.0322\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0275\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.0237\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.0209\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0188\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0171\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.0155\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0140\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0126\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0113\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0103\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0094\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0087\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0081\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8750 - loss: 0.0076\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.0071\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0066\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8750 - loss: 0.0062\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0058\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.0055\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0052\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0050\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.0047\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8750 - loss: 0.0045\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0043\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0041\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0039\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0038\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8750 - loss: 0.0037\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0035\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0034\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0033\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8750 - loss: 0.0032\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0031\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0030\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0029\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0028\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0028\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0027\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0026\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8750 - loss: 0.0026\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0025\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0025\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8750 - loss: 0.0024\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0024\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.0023\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8750 - loss: 0.0023\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8750 - loss: 0.0022\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8750 - loss: 0.0022\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8750 - loss: 0.0021\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8750 - loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f9fdce2db0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "english_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love deep learning.\",\n",
    "    \"What is your name?\",\n",
    "    \"Where do you live?\"\n",
    "]\n",
    "\n",
    "tamil_sentences = [\n",
    "    \"வணக்கம், நீங்கள் எப்படி இருக்கிறீர்கள்?\",\n",
    "    \"எனக்கு ஆழ்ந்த கற்றல் பிடிக்கும்.\",\n",
    "    \"உங்கள் பெயர் என்ன?\",\n",
    "    \"நீங்கள் எங்கு வாழ்கிறீர்கள்?\"\n",
    "]\n",
    "\n",
    "# Tokenize English sentences\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(english_sentences)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
    "\n",
    "# Tokenize Tamil sentences\n",
    "tam_tokenizer = Tokenizer()\n",
    "tam_tokenizer.fit_on_texts(tamil_sentences)\n",
    "tam_vocab_size = len(tam_tokenizer.word_index) + 1\n",
    "tam_sequences = tam_tokenizer.texts_to_sequences(tamil_sentences)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_length = max(max(len(seq) for seq in eng_sequences), max(len(seq) for seq in tam_sequences))\n",
    "eng_sequences = pad_sequences(eng_sequences, maxlen=max_length, padding='post')\n",
    "tam_sequences = pad_sequences(tam_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Split input-output pairs\n",
    "X_train = eng_sequences\n",
    "y_train = tam_sequences\n",
    "\n",
    "# Define Seq2Seq Model (Encoder-Decoder)\n",
    "embedding_dim = 128\n",
    "units = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.layers.Input(shape=(max_length,))\n",
    "enc_emb = keras.layers.Embedding(eng_vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.layers.Input(shape=(max_length,))\n",
    "dec_emb = keras.layers.Embedding(tam_vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = keras.layers.LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(tam_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Compile Model\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Shift decoder input (y_train) correctly\n",
    "decoder_input_data = y_train[:, :-1]  # Remove last token\n",
    "decoder_target_data = y_train[:, 1:]  # Remove first token\n",
    "\n",
    "# Ensure shapes match\n",
    "print(\"Encoder Input Shape:\", X_train.shape)  # (num_samples, max_length)\n",
    "print(\"Decoder Input Shape:\", decoder_input_data.shape)  # (num_samples, max_length - 1)\n",
    "print(\"Decoder Target Shape:\", decoder_target_data.shape)  # (num_samples, max_length - 1)\n",
    "\n",
    "# Fix shape mismatch by adjusting max_length\n",
    "decoder_input_data = pad_sequences(decoder_input_data, maxlen=max_length, padding='post')\n",
    "decoder_target_data = pad_sequences(decoder_target_data, maxlen=max_length, padding='post')\n",
    "\n",
    "# Train Model\n",
    "model.fit([X_train, decoder_input_data], decoder_target_data, batch_size=64, epochs=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate English → Tamil\n",
    "def translate(sentence):\n",
    "    sequence = eng_tokenizer.texts_to_sequences([sentence])\n",
    "    sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
    "    states_value = model.predict([sequence, np.zeros((1, max_length))])\n",
    "    predicted_seq = np.argmax(states_value, axis=-1)[0]\n",
    "    output_sentence = ' '.join([word for word, index in tam_tokenizer.word_index.items() if index in predicted_seq])\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "பெயர் என்ன\n"
     ]
    }
   ],
   "source": [
    "# Test Translation\n",
    "print(translate(\"what is  name\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
