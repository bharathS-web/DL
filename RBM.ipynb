{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af44a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b38a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RBM Class ---\n",
    "class RBM(tf.Module):\n",
    "    def __init__(self, n_visible, n_hidden, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        # Weight and biases initialization\n",
    "        self.W = tf.Variable(tf.random.normal([n_visible, n_hidden], stddev=0.01))\n",
    "        self.h_bias = tf.Variable(tf.zeros([n_hidden]))\n",
    "        self.v_bias = tf.Variable(tf.zeros([n_visible]))\n",
    "\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.cast(tf.random.uniform(tf.shape(probs)) < probs, tf.float32)\n",
    "\n",
    "    def v_to_h(self, v):\n",
    "        h_prob = tf.nn.sigmoid(tf.matmul(v, self.W) + self.h_bias)\n",
    "        return h_prob, self.sample_prob(h_prob)\n",
    "\n",
    "    def h_to_v(self, h):\n",
    "        v_prob = tf.nn.sigmoid(tf.matmul(h, tf.transpose(self.W)) + self.v_bias)\n",
    "        return v_prob, self.sample_prob(v_prob)\n",
    "\n",
    "    def contrastive_divergence(self, v0, lr=0.01):\n",
    "        h0_prob, h0_sample = self.v_to_h(v0)\n",
    "        v1_prob, v1_sample = self.h_to_v(h0_sample)\n",
    "        h1_prob, _ = self.v_to_h(v1_sample)\n",
    "\n",
    "        # Weight and bias updates\n",
    "        W_update = tf.matmul(tf.transpose(v0), h0_prob) - tf.matmul(tf.transpose(v1_sample), h1_prob)\n",
    "        self.W.assign_add(lr * W_update / tf.cast(tf.shape(v0)[0], tf.float32))\n",
    "        self.v_bias.assign_add(lr * tf.reduce_mean(v0 - v1_sample, axis=0))\n",
    "        self.h_bias.assign_add(lr * tf.reduce_mean(h0_prob - h1_prob, axis=0))\n",
    "\n",
    "        loss = tf.reduce_mean(tf.square(v0 - v1_prob))\n",
    "        return loss\n",
    "\n",
    "    def forward(self, v):\n",
    "        h_prob, _ = self.v_to_h(v)\n",
    "        return h_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a8b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preprocessing ---\n",
    "def preprocess(x):\n",
    "    x = x.astype(np.float32) / 255.\n",
    "    return x.reshape(-1, 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9a9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ae66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Function ---\n",
    "def train_rbm(rbm, data, epochs=5, batch_size=64, lr=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = tf.convert_to_tensor(data[i:i+batch_size])\n",
    "            loss = rbm.contrastive_divergence(batch, lr)\n",
    "            losses.append(loss.numpy())\n",
    "        print(f\"RBM {rbm.n_visible}->{rbm.n_hidden} | Epoch {epoch+1}, Loss: {np.mean(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d816b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gibbs Sampling ---\n",
    "def gibbs_sampling(rbm, steps=100, v_init=None):\n",
    "    if v_init is None:\n",
    "        v = tf.cast(tf.random.uniform((1, rbm.n_visible)) < 0.5, tf.float32)\n",
    "    else:\n",
    "        v = tf.identity(v_init)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        h_prob, h_sample = rbm.v_to_h(v)\n",
    "        v_prob, v_sample = rbm.h_to_v(h_sample)\n",
    "        v = v_sample\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5faf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize Sample ---\n",
    "def show_sample(sample):\n",
    "    plt.imshow(sample.numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95db3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create RBM ---\n",
    "rbm = RBM(784, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddfb8124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM 784->256 | Epoch 1, Loss: 0.0184\n",
      "RBM 784->256 | Epoch 2, Loss: 0.0178\n",
      "RBM 784->256 | Epoch 3, Loss: 0.0174\n",
      "RBM 784->256 | Epoch 4, Loss: 0.0169\n",
      "RBM 784->256 | Epoch 5, Loss: 0.0165\n"
     ]
    }
   ],
   "source": [
    "#  --- Train RBM ---\n",
    "train_rbm(rbm, x_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7d164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Generate and Show Image ---\n",
    "sample = gibbs_sampling(rbm, steps=100)\n",
    "show_sample(sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
